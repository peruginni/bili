## To do for MVP

- Working text input
- Working translation of snap, key is to show translation just for known words
    - Each item is component that will solve translation on its own tempo, own actor, queue... using shared storage, but separate processing.
    - To create UI and view model, worker, service... split to small bits and orchestrate in view model using async await
- Working snap detail UI figure out what is key, to express some words are known


## Ideas for future

- Group snaps by moments, relevant questions at same time, using ondevice summarisation via AI

